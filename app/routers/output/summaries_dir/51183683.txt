photon losses are among the strongest imperfections affecting multi - photon interference . despite their importance , little is known about their effect on boson sampling experiments . in this work we show that using classical computers , one can efficiently simulate multi - photon interference in all architectures that suffer from an exponential decay of the transmission with the depth of the circuit , such as integrated photonic circuits or optical fibers . we prove that either the depth of the circuit is large enough that it can be simulated by thermal noise with an algorithm running in polynomial time , or it is shallow enough that a tensor network simulation runs in quasi - polynomial time . this result suggests that in order to implement a quantum advantage experiment with single - photons and linear optics new experimental platforms may be needed .