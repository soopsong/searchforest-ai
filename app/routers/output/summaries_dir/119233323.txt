data compression can be achieved by reducing the dimensionality of high - dimensional but approximately low - rank datasets , which may in fact be described by the variation of a much smaller number of parameters . it often serves as a preprocessing step to surmount the curse of dimensionality and to gain efficiency , and thus it plays an important role in machine learning and data mining . in this paper , we present a quantum algorithm that compresses an exponentially large high - dimensional but approximately low - rank dataset in quantum parallel , by dimensionality reduction ( dr ) based on principal component analysis ( pca ) , the most popular classical dr algorithm . we show that the proposed algorithm achieves exponential speedup over the classical pca algorithm when the original dataset are projected onto a polylogarithmically low - dimensional space . the compressed dataset can then be further processed to implement other tasks of interest , with significantly less quantum resources . as examples , we apply this algorithm to reduce data dimensionality for two important quantum machine learning algorithms , quantum support vector machine and quantum linear regression for prediction . this work demonstrates that quantum machine learning can be released from the curse of dimensionality to solve problems of practical importance .