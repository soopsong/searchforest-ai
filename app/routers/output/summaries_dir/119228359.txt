we provide a general method for efficiently simulating time - dependent hamiltonian dynamics on a circuit - model based quantum computer . our approach is based on approximating the truncated dyson series of the evolution operator , extending the earlier proposal by berry to evolution generated by explicitly time - dependent hamiltonians . two alternative strategies are proposed to implement time ordering while exploiting the superposition principle for sampling the hamiltonian at different times . the resource cost of our simulation algorithm retains the optimal logarithmic dependence on the inverse of the desired precision .