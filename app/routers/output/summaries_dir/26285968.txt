we consider the problem of finite - horizon optimal control of a discrete linear time - varying system subject to a stochastic disturbance and fully observable state . the initial state of the system is drawn from a known gaussian distribution , and the final state distribution is required to reach a given target gaussian distribution , while minimizing the expected value of the control effort . we derive the linear optimal control policy by first presenting an efficient solution for the diffusion - less case , and we then solve the case with diffusion by reformulating the system as a superposition of diffusion - less systems . this reformulation leads to a simple condition for the solution , which can be effectively solved using numerical methods . we show that the resulting solution coincides with a lqg problem with particular terminal cost weight matrix . this fact provides an additional justification for using a linear in state controller . in addition , it allows an efficient iterative implementation of the controller .