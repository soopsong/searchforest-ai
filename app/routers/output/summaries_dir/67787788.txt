we introduce a new quantum optimization algorithm for dense linear programming problems , which can be seen as the quantization of the interior point predictor - corrector algorithm \cite{predictor - corrector } using a quantum linear system algorithm \cite{densehhl } . the ( worst case ) work complexity of our method is , up to polylogarithmic factors , $ o(l\sqrt{n}(n+m)\bar{||m||_f}\bar{\kappa}^2\epsilon^{-2})$ for $ n$ the number of variables in the cost function , $ m$ the number of constraints , $ \epsilon^{-1}$ the target precision , $ l$ the bit length of the input data , $ \bar{||m||_f}$ an upper bound to the frobenius norm of the linear systems of equations that appear , $ ||m||_f$ , and $ \bar{\kappa}$ an upper bound to the condition number $ \kappa$ of those systems of equations . this represents a quantum speed - up in the number $ n$ of variables in the cost function with respect to the comparable classical interior point algorithms when the initial matrix of the problem $ a$ is dense and we substitute the quantum part of the algorithm by classical algorithms such as conjugate gradient descent , what would mean the whole algorithm has complexity $ o(l\sqrt{n}(n+m)^2\bar{\kappa } \log(\epsilon^{-1}))$ , or with exact methods , at least $ o(l\sqrt{n}(n+m)^{2.373})$. also , in contrast with any quantum linear system algorithm , the algorithm described in this article outputs a classical description of the solution vector , and the value of the optimal solution . finally , the dependence on the target precision can be lowered to $ \text{poly}\log(\epsilon^{-1})$ , if the last ( constant number of ) iterations are performed classically .