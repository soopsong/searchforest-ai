quantum boltzmann machines are natural quantum generalizations of boltzmann machines that are expected to be more expressive than their classical counterparts , as evidenced both numerically for small systems and asymptotically under various complexity theoretic assumptions . however , training quantum boltzmann machines using gradient - based methods requires sampling observables in quantum thermal distributions , a problem that is np - hard . in this work , we find that the locality of the gradient observables gives rise to an efficient sampling method based on the eigenstate thermalization hypothesis , and thus through hamiltonian simulation an efficient method for training quantum boltzmann machines on near - term quantum devices . furthermore , under realistic assumptions on the moments of the data distribution to be modeled , the distribution sampled using our algorithm is approximately the same as that of an ideal quantum boltzmann machine . we demonstrate numerically that under the proposed training scheme , quantum boltzmann machines capture multimodal bernoulli distributions better than classical restricted boltzmann machines with the same connectivity structure . we also provide numerical results on the robustness of our training scheme with respect to noise .