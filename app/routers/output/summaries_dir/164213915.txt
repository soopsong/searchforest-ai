research on quantum computing has recently gained significant momentum since first physical devices became available . many quantum algorithms make use of so - called oracles that implement boolean functions and are queried with highly superposed input states in order to evaluate the implemented boolean function for many different input patterns in parallel . to simplify or enable a realization of these oracles in quantum logic in the first place , the boolean reversible functions to be realized usually need to be broken down into several non - reversible sub - functions . however , since quantum logic is inherently reversible , these sub - functions have to be realized in a reversible fashion by adding further qubits in order to make the output patterns distinguishable ( a process that is also known as embedding ) . this usually results in a significant increase of the qubits required in total . in this work , we show how this overhead can be significantly reduced by utilizing coding . more precisely , we prove that one additional qubit is always enough to embed any non - reversible function into a reversible one by using a variable - length encoding of the output patterns . moreover , we characterize those functions that do not require an additional qubit at all . the made observations show that coding often allows one to undercut the usually considered minimum of additional qubits in sub - functions of oracles by far .