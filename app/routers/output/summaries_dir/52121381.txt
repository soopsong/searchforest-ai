the recently proposed quantum language model ( qlm ) aimed at a principled approach to modeling term dependency by applying the quantum probability theory . the latest development for a more effective qlm has adopted word embeddings as a kind of global dependency information and integrated the quantum - inspired idea in a neural network architecture . while these quantum - inspired lms are theoretically more general and also practically effective , they have two major limitations . first , they have not taken into account the interaction among words with multiple meanings , which is common and important in understanding natural language text . second , the integration of the quantum - inspired lm with the neural network was mainly for effective training of parameters , yet lacking a theoretical foundation accounting for such integration . to address these two issues , in this paper , we propose a quantum many - body wave function ( qmwf ) inspired language modeling approach . the qmwf inspired lm can adopt the tensor product to model the aforesaid interaction among words . it also enables us to reveal the inherent necessity of using convolutional neural network ( cnn ) in qmwf language modeling . furthermore , our approach delivers a simple algorithm to represent and match text / sentence pairs . systematic evaluation shows the effectiveness of the proposed qmwf - lm algorithm , in comparison with the state of the art quantum - inspired lms and a couple of cnn - based methods , on three typical question answering ( qa ) datasets .