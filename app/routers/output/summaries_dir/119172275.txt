in this work we provide a computationally tractable procedure for designing affine control policies , applied to constrained , discrete - time , partially observable , linear systems subject to set bounded disturbances , stochastic noise and potentially markovian switching over a finite horizon . we investigate the situation when performance specifications are expressed via averaged quadratic inequalities on the random state - control trajectory . our methodology also applies to steering the density of the state - control trajectory under set bounded uncertainty . our developments are based on expanding the notion of affine policies that are functions of the so - called"purified outputs " , to the class of markov jump linear systems . this re - parametrization of the set of policies , induces a bi - affine structure in the state and control variables that can further be exploited via robust optimization techniques , with the approximate inhomogeneous $ s$-lemma being the cornerstone . tractability is understood in the sense that for each type of performance specification considered , an explicit convex program for selecting the parameters specifying the control policy is provided . our contributions to the existing literature on the subject of robust constrained control lies in the fact that we are addressing a wider class of systems than the ones already studied , by including markovian switching , and the consideration of quadratic inequalities rather than just linear ones . our work expands on the previous investigations on finite horizon covariance control by addressing the robustness issue and the possibility that the full state may not be available , therefore enabling the steering of the state - control trajectory density in the presence of disturbances under partial observation .