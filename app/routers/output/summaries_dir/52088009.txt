we analytically and numerically investigate the performance of weak - value amplification ( wva ) and related parameter estimation methods in the presence of temporally correlated noise . wva is a special instance of a general measurement strategy that involves sorting data into separate subsets based on the outcome of a second"partitioning"measurement . using a simplified noise model that can be analyzed exactly together with optimal statistical estimators , we compare wva to a conventional measurement method . we find that introducing wva indeed yields a much lower variance of the parameter of interest than does the conventional technique , optimized in the absence of any partitioning measurements . in contrast , a statistically optimal analysis that employs partitioning measurements , incorporating all partitioned results and their known correlations , is found to yield an improvement -- typically slight -- over the noise reduction achieved by wva . this is because the simple wva technique is not tailored to a given noise environment and therefore does not make use of correlations between the different partitions . we also compare wva to traditional background subtraction , a familiar technique where measurement outcomes are partitioned to eliminate unknown offsets or errors in calibration . surprisingly , in our model background subtraction turns out to be a special case of the optimal partitioning approach in the balanced case , possessing a similar typically slight advantage over wva . these results give deeper insight into the role of partitioning measurements , with or without post - selection , in enhancing measurement precision , which some have found puzzling . we finish by presenting numerical results to model a more realistic laboratory situation of time - decaying correlations , showing our conclusions hold for a wide range of statistical models .