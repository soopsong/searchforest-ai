#!/usr/bin/env python3
"""
Step 6:  build cluster centroids, FAISS index, and keyword meta
Inputs
  â€¢ indices/paper_embed.npy      â€“ (N, 512) float32
  â€¢ indices/cluster_labels.npy   â€“ (N,)     int32
  â€¢ indices/pid2idx.pkl          â€“ {paper_id: row_idx}
  â€¢ indices/text_emb.npz         â€“ paper_id â†’ 384-d text vec (for TF-IDF)
Outputs
  â€¢ indices/cluster_centroids.npy    â€“ (C, 512) float32
  â€¢ indices/cluster.index            â€“ FAISS IndexFlatIP on centroids
  â€¢ indices/cluster_meta.json        â€“ {cid: {size, keywords}}
"""
import numpy as np, pickle, json, faiss, pathlib, tqdm
from sklearn.feature_extraction.text import TfidfVectorizer
from sentence_transformers import SentenceTransformer, util
import itertools, re, collections

EMB_PATH   = pathlib.Path("indices/paper_embed.npy")
LABEL_PATH = pathlib.Path("indices/cluster_labels.npy")
PID_MAP    = pathlib.Path("indices/pid2idx.pkl")
TEXT_PATH  = pathlib.Path("indices/text_emb.npz")

OUT_CENT   = pathlib.Path("indices/cluster_centroids.npy")
OUT_INDEX  = pathlib.Path("indices/cluster.index")
OUT_META   = pathlib.Path("indices/cluster_meta.json")

# â”€â”€ load â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
emb     = np.load(EMB_PATH)                     # (N, 512)
labels  = np.load(LABEL_PATH)                   # (N,)
pid2idx = pickle.load(PID_MAP.open("rb"))
text_npz= np.load(TEXT_PATH)

print("ğŸ”¹ group by cluster â€¦")
clusters = {}
for pid, idx in pid2idx.items():
    cid = int(labels[idx])
    clusters.setdefault(cid, []).append(pid)

# â”€â”€ centroid & keywords â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
centroids, meta = [], {}
tfidf = TfidfVectorizer(stop_words="english", max_features=40_000)

for cid, pids in tqdm.tqdm(clusters.items(), desc="centroid/keywords"):
    idxs = [pid2idx[p] for p in pids]
    cent = emb[idxs].mean(0, dtype="float32")
    centroids.append(cent)

    # í‚¤ì›Œë“œ: í´ëŸ¬ìŠ¤í„° ë…¼ë¬¸ì˜ abstract í…ìŠ¤íŠ¸ë¡œ TF-IDF
    docs = [text_npz[p] for p in pids if p in text_npz]
    kws  = []
    if docs:
        X = tfidf.fit_transform([v.tobytes().decode("utf-8","ignore")
                                 for v in docs])
        sums = np.asarray(X.sum(0)).ravel()
        order= sums.argsort()[::-1][:20]
        kws  = tfidf.get_feature_names_out()[order].tolist()

    meta[cid] = {"size": len(pids), "keywords": kws}

# â”€â”€ save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
centroids = np.vstack(centroids).astype("float32")
np.save(OUT_CENT, centroids)

index = faiss.IndexFlatIP(centroids.shape[1])
index.add(centroids)
faiss.write_index(index, str(OUT_INDEX))

json.dump(meta, OUT_META.open("w"))
print("âœ“ centroids:", centroids.shape,
      "/ index & meta saved to indices/")
