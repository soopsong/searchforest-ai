#!/usr/bin/env python3
"""
Step 2: embed abstract text for every node in graph_raw.gpickle
Outputs
  â€¢ indices/text_emb.npz   â€“  key = paper_id, value = np.ndarray(float32, 384)
  â€¢ indices/pid2idx.pkl    â€“  {paper_id: row_idx}  (í›„ì† ë‹¨ê³„ìš©)
"""
import pathlib, tqdm, networkx as nx, numpy as np, pickle, orjson
from sentence_transformers import SentenceTransformer

GRAPH_PATH = pathlib.Path("indices/graph_raw.gpickle")
OUT_EMB    = pathlib.Path("indices/text_emb.npz")
OUT_MAP    = pathlib.Path("indices/pid2idx.pkl")
MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
BATCH      = 512                      # GPU=2-4 GB â†’ 512; CPU â†’ 64 ì¶”ì²œ

print("ğŸ”¹ load graph â€¦")
G = nx.read_gpickle(GRAPH_PATH)

print("ğŸ”¹ collect abstract texts â€¦")
pids, texts = [], []

# collect abstract texts â€¦
for pid, data in G.nodes(data=True):
    abstract = data.get("abstract") or ""

    # ë¦¬ìŠ¤íŠ¸(ë˜ëŠ” ë¦¬ìŠ¤íŠ¸-ì˜¤ë¸Œ-ë¦¬ìŠ¤íŠ¸) â†’ ë¬¸ìì—´
    if isinstance(abstract, list):
        if abstract and isinstance(abstract[0], list):          # [[sent1,sent2], [sent3]]
            abstract = " ".join(sum(abstract, []))
        else:                                         # ["sent1", "sent2", ...]
            abstract = " ".join(abstract)
    abstract = abstract.strip()

    if abstract:
        pids.append(pid)
        texts.append(abstract)

print(f"  {len(texts):,} / {G.number_of_nodes():,} nodes have abstract")

print("ğŸ”¹ load SBERT model:", MODEL_NAME)
device_id = 0           # 0ë²ˆ GPU
model = SentenceTransformer(MODEL_NAME, device=f"cuda:{device_id}")

def batched(seq, size):
    for i in range(0, len(seq), size):
        yield seq[i:i+size]

emb_list = []
for chunk in tqdm.tqdm(list(batched(texts, BATCH)), desc="encode"):
    vec = model.encode(chunk, normalize_embeddings=True, show_progress_bar=False)
    emb_list.append(vec.astype("float32"))

emb = np.vstack(emb_list)           # (N, 384)
print("  final shape:", emb.shape)

# ì €ì¥
np.savez_compressed(OUT_EMB, **{pid: v for pid, v in zip(pids, emb)})
pickle.dump({pid: i for i, pid in enumerate(pids)}, OUT_MAP.open("wb"))
print(f"âœ“ saved â†’ {OUT_EMB}  /  {OUT_MAP}")
